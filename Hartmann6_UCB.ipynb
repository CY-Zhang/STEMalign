{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "497db9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.acquisition import UpperConfidenceBound\n",
    "from botorch.acquisition.monte_carlo import qExpectedImprovement, qNoisyExpectedImprovement\n",
    "from botorch.sampling.samplers import SobolQMCNormalSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "NOISE_SE = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05f95c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the function to be maximized\n",
    "from botorch.test_functions import Hartmann\n",
    "neg_hartmann6 = Hartmann(negate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a3058040",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_initial_data(n):\n",
    "    # generate training data\n",
    "    train_x = torch.rand(n, 6, device=device, dtype=dtype)\n",
    "    exact_obj = neg_hartmann6(train_x).unsqueeze(-1)  # add output dimension\n",
    "    train_obj = exact_obj + NOISE_SE * torch.randn_like(exact_obj)\n",
    "    best_observed_value = train_x.max().item()\n",
    "    return train_x, train_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a392c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize training data and the model\n",
    "train_X, train_Y = generate_initial_data(n=10)\n",
    "\n",
    "gp = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "fit_gpytorch_model(mll)\n",
    "UCB = UpperConfidenceBound(gp, beta = 0.1)\n",
    "candidate, acq_value = optimize_acqf(\n",
    "        UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "338a2367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0457, 0.1829, 0.0935, 0.6694, 0.1073, 0.6989]])\n",
      "\n",
      "Batch  1: best_value = (0.64), time = 0.22.tensor([[0.0201, 0.2234, 0.0421, 0.6396, 0.2546, 0.7374]])\n",
      "\n",
      "Batch  2: best_value = (0.64), time = 0.44.tensor([[0.0917, 0.1983, 0.1672, 0.6350, 0.0344, 0.6170]])\n",
      "\n",
      "Batch  3: best_value = (0.64), time = 0.25.tensor([[0.6006, 0.5928, 0.8311, 0.3431, 0.0000, 0.0094]])\n",
      "\n",
      "Batch  4: best_value = (0.64), time = 0.22.tensor([[0.5767, 0.6221, 0.7909, 0.4261, 0.0000, 0.0084]])\n",
      "\n",
      "Batch  5: best_value = (0.89), time = 0.21.tensor([[0.6572, 0.5380, 0.9214, 0.1754, 0.0000, 0.0078]])\n",
      "\n",
      "Batch  6: best_value = (0.89), time = 0.18.tensor([[0.5609, 0.4458, 0.8834, 0.1684, 0.0000, 0.0490]])\n",
      "\n",
      "Batch  7: best_value = (0.89), time = 0.40.tensor([[0.0348, 0.1480, 0.0867, 0.7037, 0.0427, 0.7130]])\n",
      "\n",
      "Batch  8: best_value = (0.89), time = 0.21.tensor([[0.7355, 0.6900, 0.9060, 0.2905, 0.0299, 0.0000]])\n",
      "\n",
      "Batch  9: best_value = (0.89), time = 0.19.tensor([[0.1170, 0.2672, 0.1835, 0.5742, 0.1571, 0.5899]])\n",
      "\n",
      "Batch 10: best_value = (0.89), time = 0.21.tensor([[0.8999, 0.8824, 0.2877, 0.7655, 0.9872, 0.1939]])\n",
      "\n",
      "Batch 11: best_value = (0.89), time = 0.30.tensor([[0.1102, 0.2635, 0.1764, 0.5754, 0.1578, 0.5959]])\n",
      "\n",
      "Batch 12: best_value = (0.89), time = 0.28.tensor([[0.1282, 0.2851, 0.2002, 0.5495, 0.1687, 0.5665]])\n",
      "\n",
      "Batch 13: best_value = (0.91), time = 0.35.tensor([[0.1345, 0.2965, 0.2102, 0.5330, 0.1756, 0.5510]])\n",
      "\n",
      "Batch 14: best_value = (0.99), time = 0.30.tensor([[0.1248, 0.2988, 0.2059, 0.5158, 0.1759, 0.5426]])\n",
      "\n",
      "Batch 15: best_value = (1.05), time = 0.29.tensor([[0.0767, 0.2799, 0.1666, 0.4942, 0.1639, 0.5524]])\n",
      "\n",
      "Batch 16: best_value = (1.06), time = 0.53.tensor([[0.0410, 0.2876, 0.1520, 0.4268, 0.1627, 0.5196]])\n",
      "\n",
      "Batch 17: best_value = (1.17), time = 0.30.tensor([[0.0255, 0.2822, 0.1400, 0.4183, 0.1587, 0.5213]])\n",
      "\n",
      "Batch 18: best_value = (1.17), time = 0.59.tensor([[0.0175, 0.2743, 0.1298, 0.4270, 0.1556, 0.5327]])\n",
      "\n",
      "Batch 19: best_value = (1.17), time = 0.69.tensor([[0.0198, 0.2780, 0.1431, 0.4625, 0.1586, 0.5158]])\n",
      "\n",
      "Batch 20: best_value = (1.17), time = 0.68.tensor([[0.0676, 0.2887, 0.1791, 0.4979, 0.1651, 0.5190]])\n",
      "\n",
      "Batch 21: best_value = (1.17), time = 1.48.tensor([[0.0486, 0.2785, 0.1228, 0.3610, 0.1567, 0.5654]])\n",
      "\n",
      "Batch 22: best_value = (1.41), time = 0.30.tensor([[0.0400, 0.2712, 0.1138, 0.3722, 0.1550, 0.5750]])\n",
      "\n",
      "Batch 23: best_value = (1.41), time = 0.56.tensor([[0.0000, 0.3111, 0.1083, 0.4529, 0.1564, 0.5194]])\n",
      "\n",
      "Batch 24: best_value = (1.41), time = 0.39.tensor([[0.0045, 0.2193, 0.1534, 0.4363, 0.1610, 0.5270]])\n",
      "\n",
      "Batch 25: best_value = (1.41), time = 0.60.tensor([[0.0000, 0.1698, 0.1627, 0.4300, 0.1625, 0.5166]])\n",
      "\n",
      "Batch 26: best_value = (1.41), time = 0.64.tensor([[0.0000, 0.2064, 0.1692, 0.4335, 0.1599, 0.5481]])\n",
      "\n",
      "Batch 27: best_value = (1.41), time = 0.48.tensor([[0.0000, 0.2156, 0.0986, 0.4689, 0.1593, 0.5122]])\n",
      "\n",
      "Batch 28: best_value = (1.41), time = 0.58.tensor([[0.0000, 0.2141, 0.0903, 0.4776, 0.1585, 0.5235]])\n",
      "\n",
      "Batch 29: best_value = (1.41), time = 0.38.tensor([[0.0000, 0.2654, 0.2182, 0.4032, 0.1590, 0.5679]])\n",
      "\n",
      "Batch 30: best_value = (1.41), time = 0.28.tensor([[0.0000, 0.2706, 0.2650, 0.3781, 0.1586, 0.5816]])\n",
      "\n",
      "Batch 31: best_value = (1.50), time = 0.65.tensor([[0.0000, 0.2700, 0.1668, 0.4063, 0.1701, 0.4943]])\n",
      "\n",
      "Batch 32: best_value = (1.50), time = 0.37.tensor([[0.0000, 0.2877, 0.1564, 0.4341, 0.1586, 0.5764]])\n",
      "\n",
      "Batch 33: best_value = (1.50), time = 0.45.tensor([[0.0610, 0.2167, 0.1537, 0.3955, 0.1616, 0.5148]])\n",
      "\n",
      "Batch 34: best_value = (1.50), time = 0.59.tensor([[0.0924, 0.1955, 0.1562, 0.3647, 0.1659, 0.4938]])\n",
      "\n",
      "Batch 35: best_value = (1.50), time = 0.34.tensor([[0.0783, 0.2013, 0.1567, 0.3763, 0.1632, 0.5064]])\n",
      "\n",
      "Batch 36: best_value = (1.50), time = 0.34.tensor([[0.0443, 0.2215, 0.1622, 0.3940, 0.1545, 0.4888]])\n",
      "\n",
      "Batch 37: best_value = (1.50), time = 0.46.tensor([[0.0516, 0.2062, 0.1545, 0.4001, 0.1655, 0.5669]])\n",
      "\n",
      "Batch 38: best_value = (1.50), time = 0.39.tensor([[0.0000, 0.2309, 0.1682, 0.4239, 0.1626, 0.4901]])\n",
      "\n",
      "Batch 39: best_value = (1.50), time = 0.54."
     ]
    }
   ],
   "source": [
    "bounds = torch.stack([torch.zeros(6), torch.ones(6)])\n",
    "gp = SingleTaskGP(train_X, train_Y)\n",
    "mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "best_observed_value = []\n",
    "\n",
    "for iteration in range(1, 40):\n",
    "    t0 = time.time()\n",
    "    \n",
    "    fit_gpytorch_model(mll)\n",
    "    \n",
    "    UCB = UpperConfidenceBound(gp, beta = 1)    \n",
    "    candidate, acq_value = optimize_acqf(\n",
    "        UCB, bounds=bounds, q=1, num_restarts=5, raw_samples=20,\n",
    "    )\n",
    "    new_x = candidate.detach()\n",
    "    print(new_x)\n",
    "    new_y = neg_hartmann6(new_x).unsqueeze(-1)\n",
    "    new_y = new_y + NOISE_SE * torch.randn_like(new_y)\n",
    "    train_X = torch.cat([train_X, new_x])\n",
    "    train_Y = torch.cat([train_Y, new_y])\n",
    "    best_value = neg_hartmann6(train_X).max()\n",
    "    best_observed_value.append(best_value)\n",
    "    \n",
    "    # update GP model using dataset with new datapoint\n",
    "    gp = SingleTaskGP(train_X, train_Y)\n",
    "    mll = ExactMarginalLogLikelihood(gp.likelihood, gp)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    print(\n",
    "            f\"\\nBatch {iteration:>2}: best_value = \"\n",
    "            f\"({best_value:>4.2f}), \"\n",
    "            f\"time = {t1-t0:>4.2f}.\", end=\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1db3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
